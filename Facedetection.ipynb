{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a453b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Image preprocessing for TRAINING and TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb2317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifing the folder where the image are present\n",
    "traning_image='../FaceDetection/Face Images/Final Training Images'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b223f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traning_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7aa557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 images belonging to 16 classes.\n",
      "Found 244 images belonging to 16 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'face1': 0,\n",
       " 'face10': 1,\n",
       " 'face11': 2,\n",
       " 'face12': 3,\n",
       " 'face13': 4,\n",
       " 'face14': 5,\n",
       " 'face15': 6,\n",
       " 'face16': 7,\n",
       " 'face2': 8,\n",
       " 'face3': 9,\n",
       " 'face4': 10,\n",
       " 'face5': 11,\n",
       " 'face6': 12,\n",
       " 'face7': 13,\n",
       " 'face8': 14,\n",
       " 'face9': 15}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_generator=ImageDataGenerator(\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    "\n",
    ")\n",
    "# Defining pre-processing transformations on raw images of training data\n",
    "# These hyper parameters helps to generate slightly twisted versions\n",
    "# of the original image, which leads to a better model, since it learns\n",
    "# on the good and bad mix of images\n",
    "\n",
    "test_data_generator=ImageDataGenerator()\n",
    "# Defining pre-processing transformations on raw images of testing data\n",
    "# No transformations are done on the testing images\n",
    "\n",
    "\n",
    "\n",
    "#Generating the traning data\n",
    "traning_set=train_data_generator.flow_from_directory(\n",
    "    traning_image,\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "#Generating the test data\n",
    "test_set=train_data_generator.flow_from_directory(\n",
    "    traning_image,\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "#Printing the class label for each face\n",
    "test_set.class_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c68e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face1': 0,\n",
       " 'face10': 1,\n",
       " 'face11': 2,\n",
       " 'face12': 3,\n",
       " 'face13': 4,\n",
       " 'face14': 5,\n",
       " 'face15': 6,\n",
       " 'face16': 7,\n",
       " 'face2': 8,\n",
       " 'face3': 9,\n",
       " 'face4': 10,\n",
       " 'face5': 11,\n",
       " 'face6': 12,\n",
       " 'face7': 13,\n",
       " 'face8': 14,\n",
       " 'face9': 15}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_class_indices=traning_set.class_indices\n",
    "training_class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328450aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Face and its ID: {0: 'face1', 1: 'face10', 2: 'face11', 3: 'face12', 4: 'face13', 5: 'face14', 6: 'face15', 7: 'face16', 8: 'face2', 9: 'face3', 10: 'face4', 11: 'face5', 12: 'face6', 13: 'face7', 14: 'face8', 15: 'face9'}\n",
      "Number of neurons: 16\n"
     ]
    }
   ],
   "source": [
    "#creating a mapping for index and face names\n",
    "\n",
    "result_indices_map={}\n",
    "\n",
    "\n",
    "# Here first line of for loop is getting the indices values and key i.e:) {'face1':0}\n",
    "for face_value,face_name in zip(training_class_indices.values(),training_class_indices.keys()):\n",
    "    result_indices_map[face_value]=face_name  # Here to mapping the values to keys and keys to  values i.e: {0:'face1'}\n",
    "    \n",
    "    \n",
    "# saving the map for feature reference\n",
    "import pickle\n",
    "\n",
    "with open('result_indices_map.pkl','wb') as fileWriteStream:\n",
    "    pickle.dump(result_indices_map,fileWriteStream)\n",
    "\n",
    "# Here we get recent mapping and corresponding face name of it\n",
    "print('Mapping of Face and its ID:',result_indices_map)\n",
    "\n",
    "\n",
    "# Number of neurons for the output layer is equal to the number of faces\n",
    "output_neurons=len(result_indices_map)\n",
    "print('Number of neurons:',output_neurons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7206bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Lets start to build CNN model\n",
    "\n",
    "# Before creating the CNN we have to import some of the importent lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb58261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 4s 369ms/step - loss: 112.5598 - accuracy: 0.0574 - val_loss: 2.7473 - val_accuracy: 0.1598\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 2.6651 - accuracy: 0.1393 - val_loss: 2.6327 - val_accuracy: 0.2295\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 2.5318 - accuracy: 0.2664 - val_loss: 1.9997 - val_accuracy: 0.4303\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 3s 352ms/step - loss: 1.8174 - accuracy: 0.4549 - val_loss: 1.2456 - val_accuracy: 0.6230\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 1.1499 - accuracy: 0.6762 - val_loss: 0.6414 - val_accuracy: 0.8279\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 0.6829 - accuracy: 0.7869 - val_loss: 0.6841 - val_accuracy: 0.7951\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.5342 - accuracy: 0.8402 - val_loss: 0.3441 - val_accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 0.2537 - accuracy: 0.9262 - val_loss: 0.1285 - val_accuracy: 0.9590\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.0835 - accuracy: 0.9754 - val_loss: 0.0855 - val_accuracy: 0.9754\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 3s 385ms/step - loss: 0.1401 - accuracy: 0.9549 - val_loss: 0.0978 - val_accuracy: 0.9713\n",
      "Total time takes:{} 0 Minutes.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPool2D,Flatten,Dense\n",
    "\n",
    "## Initializing the CNN model\n",
    "model=Sequential()\n",
    "\n",
    "''' STEP--1 Convolution\n",
    "# Adding the first layer of CNN\n",
    "# we are using the format (64,64,3) because we are using TensorFlow backend\n",
    "# It means 3 matrix of size (64X64) pixels representing Red, Green and Blue components of pixels'''\n",
    "model.add(Convolution2D(\n",
    "    32,\n",
    "    kernel_size=(5,5),\n",
    "    strides=(1,1),\n",
    "    input_shape=(64,64,3),\n",
    "    activation='relu'\n",
    "))\n",
    "\n",
    "# Max Pooling \n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# ADDITIONAL LAYER of CONVOLUTION for better accuracy\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    64,\n",
    "    kernel_size=(5,5),\n",
    "    strides=(1,1),\n",
    "    activation='relu'\n",
    "\n",
    "))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Flattern Layer\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected NN\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "model.add(Dense(output_neurons,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "import time\n",
    "# Measuring the time taken by the model to train\n",
    "Start_time=time.time()\n",
    "\n",
    "model.fit(\n",
    "    traning_set,\n",
    "    epochs=10,\n",
    "    validation_data=test_set,\n",
    ")\n",
    "\n",
    "End_time=time.time()\n",
    "\n",
    "print('Total time takes:{}',round((End_time-Start_time)/60),'Minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45a26b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets test our CNN model with unseen images\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "Image_test_path='../FaceDetection/Face Images/Final Testing Images/face4/3face4.jpg'\n",
    "\n",
    "test_image=image.load_img(Image_test_path,target_size=(64,64))\n",
    "test_image=image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c33161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Face: face4\n"
     ]
    }
   ],
   "source": [
    "# axis=0 specifies that you want to add a new dimension at the beginning of the array. \n",
    "#This effectively adds a new \"batch\" dimension. \n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "result=model.predict(test_image,verbose=0)\n",
    "\n",
    "print('Prediction Face:',result_indices_map[np.argmax(result)])\n",
    "\n",
    "#yeah.the model has predicted this face correctly.Lets try another image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c08686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 nd Prediction Face: face11\n"
     ]
    }
   ],
   "source": [
    "Image_test_path_sec='../FaceDetection/Face Images/Final Testing Images/face11/1face11.jpg'\n",
    "\n",
    "test_image_sec=image.load_img(Image_test_path_sec,target_size=(64,64))\n",
    "test_image_sec=image.img_to_array(test_image_sec)\n",
    "\n",
    "test_image_sec=np.expand_dims(test_image_sec,axis=0) \n",
    "# axis=0 specifies that you want to add a new dimension at the beginning of the array. \n",
    "#This effectively adds a new \"batch\" dimension.\n",
    "\n",
    "result=model.predict(test_image_sec,verbose=0)\n",
    "\n",
    "print('2 nd Prediction Face:',result_indices_map[np.argmax(result)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811d750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
